import os
import scipy.io as sio
import numpy as np
import h5py

from rich import print
from rich.progress import track
import matplotlib.pyplot as plt
import pandas as pd 
import seaborn as sns

from sklearn import svm
from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneOut


import settings as s

from Recording import Recording

paths = s.paths()
params = s.params()

new_rec = Recording(paths.Ksdir, paths.SoundInfo)
new_rec.clean_data(quality='mua')
print(new_rec)


def load_data_ks():
	""" Load npy files generated by Kilosort and cleaned by Phy. Also load ttls"""

	# Load files from KS directory
	spikes_times = np.load(os.path.join(paths.Ksdir,'spike_times.npy'))
	spikes_times = np.array([i[0] for i in spikes_times])
	spikes_cluster = np.load(os.path.join(paths.Ksdir,'spike_clusters.npy'))
	cluster_group = pd.read_csv(os.path.join(paths.Ksdir,'cluster_group.tsv'), delimiter='\t')
	cluster_group = cluster_group['group'].to_numpy()

	sound_info = sio.loadmat(paths.SoundInfo)

	f = open(paths.digitalin, 'rb') 
	sd_array = np.fromfile(f, np.int16)
	f.close()
	ttl_indices = np.where(np.insert(np.diff(sd_array), 0, 0) == 1)[0]

	# Not necessary to load for PSTHs
	# spikes_templates = np.load(os.path.join(paths.Ksdir,'spike_templates.npy'))
	# templates = np.load(os.path.join(paths.Ksdir,'templates.npy'))
	# spikes_amplitude = np.load(os.path.join(paths.Ksdir, 'amplitudes.npy'))
	# winv = np.load(os.path.join(paths.Ksdir,'whitening_mat_inv.npy'))
	# coords = np.load(os.path.join(paths.Ksdir,'channel_positions.npy'))


	return spikes_times, spikes_cluster, cluster_group, sound_info, ttl_indices

def clean_data(spikes_times, spikes_cluster, cluster_group, sound_info, quality='good'):
	""" Extract soundnames and remove unwanted cluster categories"""
	# Be careful with 1-indexing of matlab so remove 1
	stim_vector = np.squeeze(sound_info['StimsVector']) - 1
	sound_names = np.array([n[0] for n in np.squeeze(sound_info['SoundNames'])])

	# Get cluster numbers that are not noise
	if quality == 'good':
		usable_clusters = [i for i, clu in enumerate(cluster_group) if clu == 'good']
	elif quality =='mua':
		usable_clusters = [i for i, clu in enumerate(cluster_group) if not clu == 'noise']
	elif quality =='noise':
		usable_clusters = list(range(len(cluster_group)))


	# Clean spike timings to keep only good clusters
	usable_spikes = np.isin(spikes_cluster, usable_clusters)
	spikes_times = spikes_times[usable_spikes]
	spikes_cluster = spikes_cluster[usable_spikes]

	return usable_spikes, spikes_times, spikes_cluster, stim_vector, sound_names

def compute_svm(X, y):

	clf = svm.SVC()
	scores = cross_val_score(clf, X, y, cv=5)

	print(np.mean(scores), np.std(scores))

	return scores

def get_pop_vectors(spikes_cluster, spikes_times, stim_vector, ttl_indices, pad_after=params.pad_after, task=params.task1):
	idxs_clu = []
	for j, clu in enumerate(np.unique(spikes_cluster)):
		idxs_clu.append(np.where(spikes_cluster == clu)[0])

	# Structure of array is dict[stim_number][presentation_number] containg a number_of_cluster * spikes matrix
	d_stims = {}
	for stim in track(np.unique(stim_vector), description='Generating individual timings ...'):
		stim_ttls = ttl_indices[np.where(stim_vector == stim)[0]]
		d_stims[stim] = {}
		for i, ttl in enumerate(stim_ttls):
			spikes = spikes_times[spikes_times > ttl - params.pad_before]
			spikes = np.array(spikes[spikes < ttl + pad_after], dtype=np.int64)

			d_stims[stim][i] = [len(np.intersect1d(spikes_times[idx_clu], spikes) - ttl)/(params.fs*1000) for idx_clu in idxs_clu]


	pop_vectors = [d_stims[k] for k in task]

	return pop_vectors


sp_times, sp_cluster, clu_group, sd_info, ttl_indices = load_data_ks()
usable_sp, sp_times, sp_cluster, s_vector, sound_names = clean_data(sp_times, sp_cluster, clu_group, sd_info, quality='good')


for i, t in enumerate([params.task1, params.task2]):
	scores = []
	for p in np.arange(0.05, 1, 0.05) * params.fs:
		pop_vectors = get_pop_vectors(sp_cluster, sp_times, s_vector, ttl_indices, pad_after=p, task=t)

		X = np.array([stim[pres] for stim in pop_vectors for pres in stim])
		y = np.concatenate(([0]*8*15, [1]*8*15))


		score = compute_svm(X, y)
		scores.append([np.mean(score), np.std(score)])

	scores = np.array(scores).reshape(-1, 2)

	plt.errorbar(np.arange(0.05, 1, 0.05), scores[:, 0], label='Task {}'.format(1 if not i else 2))

plt.legend()
plt.savefig('performance_svm.png')
plt.show()


# Still need to drax psycoM curves

	
		



# Compute global N x T matrix
# dict_timings = {}
# for clu in track(usable_clusters, description='Computing individual cluster ...'):
# 	dict_timings[clu] = np.where(spikes_cluster == clu)[0]


# dict_stim_timings = {}
# for stim in track(np.unique(stim_vector), description='Generating individual timings ...'):
# 	curr_stim = np.where(stim_vector == stim)[0]
# 	dict_stim_timings[stim] = {}
# 	for i, pres in enumerate(curr_stim):
# 		ttl = ttl_indices[pres]
# 		dict_stim_timings[stim][i] = [(v[np.logical_and(v >= ttl - params.pad_before, v <= ttl + params.pad_after)] - ttl)/params.fs*1000 for v in list(dict_timings.values())]

# for stim in dict_stim_timings:
# 	curr_stim = [[sum(list(dict_stim_timings[stim][i][j])) for i in dict_stim_timings[stim]] for j in range(len(usable_clusters))]
# 	dict_stim_timings[stim] = [a for l in curr_stim for a in l if a]
# 	dict_stim_timings[stim].sort()
# # 	dict_stim_timings[stim] = [l for l in curr_stim if l]

# print([len(dict_stim_timings[stim]) for stim in dict_stim_timings])
	







# all_psth = {}
# for i in track(range(max(stim_vector)), description='Generating PSTHs...'):
# 	psths = [] 
# 	curr_stim = np.where(stim_vector == i)[0]
# 	for stim in curr_stim:
# 		curr_ttl = list(ttl_indices)[0::2][stim]

# 		curr_n_spikes = spikes_times[spikes_times > curr_ttl - params.pad_before]
# 		curr_n_spikes = np.array(curr_n_spikes[curr_n_spikes < curr_ttl + params.pad_after], dtype=np.int64)
# 		psths.append(np.array(curr_n_spikes - curr_ttl)/params.fs*1000)
	
# 	psth = [i for p in psths for i in p]
# 	all_psth[sound_names[i]] = psth



# for sound in track(all_psth, description='Drawing Figures...'):
# 	sns.set_theme(style='ticks')

# 	f, ax = plt.subplots(figsize=(7, 5))
# 	sns.despine(f)

# 	sns.histplot(data=all_psth[sound], palette='light:m_r', 
# 				 edgecolor='.3', linewidth=.5, bins=50)
# 	plt.axvline(0, color='red')
# 	ax.set_xlabel('Time (ms)')
# 	ax.set_ylabel('# of spikes')
# 	ax.set_title('{}'.format(sound[:-4]))
# 	plt.savefig(os.path.join(paths.Output, '{}.png'.format(sound[:-4])), dpi=150)
# 	plt.close()


# May be useful to get correlation matrices between histograms
